---
title: "Decision Tree for Loansharks (2014 Pennsylvania)"
author: "Anantanarayanan G Iyengar, Omkar Pawar [Please add your names here]" 
date: "4/5/2020"
output: html_notebook
---

## Global setup like working directory, data directory etc should happen here.

```{r}
library(sys)

working_directory <- getwd()

setwd(dirname(dirname(working_directory)))

writeLines("")
getwd()
# The HMDA dataset is loaded from here.
data_dir <- "D:/data"
census_data_dir = "d:/data/census"

# The models are saved in this directory.
model_path <- paste(dirname(rstudioapi::getActiveDocumentContext()$path), "models", sep = "/")
print(model_path)

# The train and test data are saved in this directory
model_data_path <- paste(dirname(rstudioapi::getActiveDocumentContext()$path), "data", sep = "/")
print(model_data_path)

```

## Install required packages.
```{r}
library(corrplot)
library(ggplot2)
library(tidyr)
library(stringr)
library(dplyr)
library(data.table)
library(mice)
library(rstudioapi)    
library(naniar)
library(caret)
library(pROC)
library(ROCR)
library(mlr)
source(paste(dirname(dirname(dirname(rstudioapi::getActiveDocumentContext()$path))), "utils/utils.r", sep="/"))

source(paste(dirname(dirname(dirname(rstudioapi::getActiveDocumentContext()$path))), "utils/model_utils.r", sep="/"))

```

# Load the imputed hmda csv file.
```{r}
# hmda_data_df_ <- fread("/Users/omkarpawar/Desktop/Data/hmda_2014_pa_imputed.csv")
#hmda_data_df <- fread("/Users/omkarpawar/Desktop/Data/PA/hmda_2014_pa_imputed.csv")

hmda_data_df <- fread(paste(data_dir, "/HMDA/2014/hmda_2014_pa_imputed.csv", sep = ""))

hmda_data_df <- as.data.frame(hmda_data_df)
df<-hmda_data_df
```

# Explore the dataframe obtained above.
```{r}
head(hmda_data_df, 20)
# Ignore action values of 4 : Application withdrawn by applicant
# 6: Loan purchased by the institution and 2: Application approved but
# not accepted. 
# The remaining action types are 1: Loan originated, 3. Application denied
# by financial institution, 5. File closed for incompleteness and 7. Preapproval
# request denied by financial institution.
hmda_data_df <- hmda_data_df[hmda_data_df$action_taken != 2 & hmda_data_df$action_taken != 4 & hmda_data_df$action_taken != 6, ]

colnames(hmda_data_df)
```

# Create dataframe based on selected column list from the source dataframe.
```{r}
hmda_data_df_for_model <- hmda_data_frame_for_model(hmda_data_df)
hmda_data_df_for_model <- process_model_df_columns(hmda_data_df_for_model)

```

# Explore the dataframe with selected columns obtained above.

```{r}
head(hmda_data_df_for_model, 20)

nrow(hmda_data_df_for_model)

```
```{r}
length(unique(df$county_code))
count_df<-summarise_at(group_by(df,county_name),vars(county_code),funs(n()))
ggplot(data = count_df , aes(x = reorder(county_name,county_code), y = county_code))+geom_bar(stat= "identity",fill = "steelblue" )+geom_text(aes(  label = (round((county_code/length(df$county_code)),4)*100)), size=2,hjust = -0.1)+coord_flip()+labs(x = "County Name" , y = "Percent of application from that county",title= "Applications per county in PA for 2014")
#ggsave("/Users/omkarpawar/Desktop/county_plot.png",width = 17,height = 12)
```

```{r}
count_df$percent <- (count_df$county_code / length(df$county_code))*100
filtered_df <- filter(count_df,percent>0.82)

ggplot(data = filtered_df , aes(x = reorder(county_name,county_code), y = county_code))+geom_bar(stat= "identity",fill = "steelblue" )+geom_text(aes(  label = round(percent,2), size=2,hjust = -0.1))+coord_flip()+labs(x = "County Name" , y = "Percent of application from that county",title= "Applications per county in PA for 2014")
#ggsave("/Users/omkarpawar/Desktop/top_25_county_plot.png",width = 17,height = 12)
```

# Train/test split.
```{r}
set.seed(400)

split_dfs <- train_test_split(hmda_data_df_for_model$loan_granted, hmda_data_df_for_model)

train <- split_dfs[[1]]
test <- split_dfs[[2]]
```


## CART Algorithm
Classification and Regression Trees (CART) split attributes based on values that minimize a loss function, such as sum of squared errors.

From the selected columns in EDA for feature importances, we select top features and build a model using those predictors. 
```{r}
library(rpart)
#Create Model
cart_model_basic <- rpart(loan_granted~applicant_race_and_ethnicity+applicant_income_000s+loan_amount_000s+preapproval+co_applicant_present+county_code+minority_population+loan_purpose+tract_to_msamd_income+applicant_sex+property_type+owner_occupancy+agency_code+rate_spread+respondent_id,train,control = rpart.control(cp = 0,minsplit = 2))

pred.model.1 <- predict(cart_model_basic,test,type = "class")
cm<-confusionMatrix(pred.model.1,test$loan_granted, positive = "yes")
draw_confusion_matrix(cm,"Loan Granted","Loan Denied")
# Prune the model
pruned  <- prune(cart_model_basic , cp = 0.0084)
pred <- predict(pruned,test,type = "class" )
cm<-confusionMatrix(pred,test$loan_granted, positive = "yes")
draw_confusion_matrix(cm, "Loan Granted" , "Loan Denied")
precision_recall(confusionMatrix(pred,test$loan_granted, positive = "yes")$table)
```

### Give the decision tree diagram
```{r}
library(rpart.plot)
rpart.plot(pruned, extra = 106)
```
# Grid Search to find the best parameters

```{r}
(dt_task <- makeClassifTask(data = train , target = "loan_granted",positive = "yes"))
```
```{r}
(dt_prob <- makeLearner('classif.rpart',predict.type = "prob"))
```


```{r}
getParamSet("classif.rpart")
```
```{r}
dt_param <- makeParamSet(
  makeDiscreteParam("minsplit",values = seq(10,20,1)),
  makeNumericParam("cp",lower = 0.00 , upper = 0.05),
  makeDiscreteParam("maxdepth",values = 15)
)
```

```{r}
ctrl = makeTuneControlGrid()
```

```{r}
rdesc = makeResampleDesc("CV",iters = 3L , stratify = TRUE)
```

```{r}
set.seed(400)
(dt_tuneparam <- tuneParams(learner = dt_prob,
                            resampling = rdesc,
                            measures = list(tpr,auc,mmce,tnr,
                                        setAggregation(tpr,test.sd)),
                            par.set = dt_param,
                            control=ctrl,
                            task = dt_task,
                            show.info =TRUE))
```
Build a model with optimal hyperparameters
```{r}
tuned_param_model_loan_to_income_ratio <- rpart(loan_granted~applicant_race_and_ethnicity+owner_occupancy+preapproval+log_loan_amount_000s+applicant_sex+county_code+tract_to_msamd_income+co_applicant_present+agency_code+minority_population+loan_purpose+rate_spread+property_type+loan_to_income_ratio+respondent_id,train,control = rpart.control(cp  = 0.0007,minsplit = 14, maxdepth = 20))

pred.model.1 <- predict(tuned_param_model_loan_to_income_ratio,test,type = "prob")
print_model_performance(pred.model.1[, 2], test, positive = "yes", negative = "no", threshold = 0.7)
dir.create(model_path, showWarnings = FALSE)
save(tuned_param_model_loan_to_income_ratio, file = paste(model_path, "/tuned_param_model_loan_to_income_ratio.rdata", sep=""))

# Prune the model
pruned  <- prune(tuned_param_model_loan_to_income_ratio , cp = 0.0084)
pred <- predict(pruned,test,type = "class" )
cm<-confusionMatrix(pred,test$loan_granted, positive = "yes")
draw_confusion_matrix(cm,"Loan Granted" , "Loan Denied")

rpart.plot(pruned, extra = 106)
```

### Model Performance
```{r}
predicted.probabilities.cart <- predict(tuned_param_model_loan_to_income_ratio,test,type = "prob")
model_performance_curves(predicted.probabilities.cart[,2],test$loan_granted)

source(paste(dirname(dirname(dirname(rstudioapi::getActiveDocumentContext()$path))), "utils/utils.r", sep="/"))

source(paste(dirname(dirname(dirname(rstudioapi::getActiveDocumentContext()$path))), "utils/model_utils.r", sep="/"))


print_model_performance(predicted.probabilities.cart[, 2], test, positive = "yes", negative = "no", threshold = 0.7)

plot(test$loan_granted,predicted.probabilities.cart, print.auc=TRUE, auc.polygon=TRUE, grid=c(0.1, 0.2),
     grid.col=c("green", "red"), max.auc.polygon=TRUE,
     auc.polygon.col="lightblue", print.thres=TRUE)
```
## Now we try a different tree algorithm. The C4.5 algorithm is an extension of the ID3 algorithm and constructs a decision tree to maximize information gain (difference in entropy).

```{r}
library(RWeka)

c4.5_model <- J48(loan_granted~applicant_race_and_ethnicity+applicant_income_000s+loan_amount_000s+preapproval+co_applicant_present+county_code+minority_population+loan_purpose+tract_to_msamd_income+applicant_sex+property_type+owner_occupancy+agency_code+rate_spread+respondent_id, train)

pred <- predict(c4.5_model,test,type = "class")
cm<-confusionMatrix(pred,test$loan_granted, positive = "yes")
draw_confusion_matrix(cm,"Loan Granted","Loan Denied")
precision_recall(confusionMatrix(pred,test$loan_granted, positive = "yes")$table)
```
### Model Performance
```{r}
predicted.probabilities.c4.5 <- predict(c4.5_model,test,type = "prob")
model_performance_curves(predicted.probabilities.c4.5[,2],test$loan_granted)
print_model_performance(predicted.probabilities.c4.5[, 2], test, positive = "yes", negative = "no", threshold = 0.5)
```
### Now lets see the parameters and add some new features like loan_to_income ratio to see if the model performance improves.

```{r}
#Create Model
cart_model_new_feature <- rpart(loan_granted~agency_code+applicant_race_and_ethnicity+log_applicant_income_000s+log_loan_amount_000s+county_code+loan_to_income_ratio+hud_median_family_income+applicant_sex,train,control = rpart.control(cp = 0))

pred.model.1 <- predict(cart_model_new_feature,test,type = "class")
confusionMatrix(pred.model.1,test$loan_granted, positive = "yes")
# Prune the model
pruned  <- prune(cart_model_new_feature , cp = 0.0084)
pred <- predict(pruned,test,type = "class" )
confusionMatrix(pred,test$loan_granted, positive = "yes")
precision_recall(confusionMatrix(pred,test$loan_granted, positive = "yes")$table)
```
# Save models

```{r}
tuned_param_model_loan_to_income_ratio <- rpart(loan_granted~applicant_race_and_ethnicity+owner_occupancy+preapproval+log_loan_amount_000s+applicant_sex+county_code+tract_to_msamd_income+co_applicant_present+agency_code+minority_population+loan_purpose+rate_spread+property_type+loan_to_income_ratio+respondent_id,train,control = rpart.control(cp  = 0.0007,minsplit = 14, maxdepth = 20))

dt_model_2014_log_income_loan_amount <- rpart(loan_granted~applicant_race_and_ethnicity+log_applicant_income_000s+log_loan_amount_000s+preapproval+co_applicant_present+county_code+tract_to_msamd_income+loan_purpose+owner_occupancy+respondent_id+minority_population+rate_spread+agency_code+applicant_sex+co_applicant_sex+property_type,train,control = rpart.control(cp  = 0.0007,minsplit = 14, maxdepth = 20))

save(tuned_param_model_loan_to_income_ratio, file = paste(model_path, "/tuned_param_model_loan_to_income_ratio.rdata", sep=""))

save(dt_model_2014_log_income_loan_amount, file = paste(model_path, "/dt_model_2014_log_income_loan_amount.rdata", sep=""))

```

